# Model-Based RL

Keys papers in model based RL from openAI spinningup

https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#citations-below

1a [12]	World Models: Ha and Schmidhuber, 2018

2 [13]	I2A (Imagination-Augmented Agents): Weber et al, 2017

3 [14]	MBMF (Model-Based RL with Model-Free Fine-Tuning): Nagabandi et al, 2017

4 [15]	MBVE (Model-Based Value Expansion): Feinberg et al, 2018


6. Model-Based RL
a. Model is Learned

[59] same as [13]	Imagination-Augmented Agents for Deep Reinforcement Learning, Weber et al, 2017. Algorithm: I2A.

[60] same as [14]	Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning, Nagabandi et al, 2017. Algorithm: MBMF.

[61] same as [15]	Model-Based Value Expansion for Efficient Model-Free Reinforcement Learning, Feinberg et al, 2018. Algorithm: MVE.

5 [62]	Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion, Buckman et al, 2018. Algorithm: STEVE.

6 [63]	Model-Ensemble Trust-Region Policy Optimization, Kurutach et al, 2018. Algorithm: ME-TRPO.

7 [64]	Model-Based Reinforcement Learning via Meta-Policy Optimization, Clavera et al, 2018. Algorithm: MB-MPO.

1b [65]	Recurrent World Models Facilitate Policy Evolution, Ha and Schmidhuber, 2018.

